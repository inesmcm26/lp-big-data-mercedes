{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PySpark DataFrames - Part 2 module you've learned how to join dataframes, perform aggregations and create pivot tables to answer business questions\n",
    "\n",
    "In this notebook there are some more of those questions that you can answer using PySpark DataFrames methods and SQL functions.\n",
    "\n",
    "Some of them will require you to look into the documentation to find the right function to use, which I think is the best way to learn how to use PySpark.\n",
    "\n",
    "So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the **preprocessed orders and products DataFrames** like you did in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"/FileStore/lp-big-data/orders-data/orders-preprocessed.csv\")\n",
    ")\n",
    "\n",
    "df_products = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"/FileStore/lp-big-data/orders-data/products-preprocessed.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the tables on the product_id column and store the result in a new dataframe called orders_products.\n",
    "\n",
    "For the exercises, ignore all orders that don't have a matching product in the products dataframe.\n",
    "\n",
    "Then, show the first 5 rows of the orders_products dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_products = (\n",
    "    df_orders.join(\n",
    "        df_products,\n",
    "        on=['product_id'],\n",
    "        how='inner'\n",
    "    )\n",
    ")\n",
    "\n",
    "df_orders_products.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do fast deliveries have more revenue than the other ones? And are they more profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_orders_products\n",
    "    # .withColumn('total_price', f.col('cost_per_unit') * f.col('amount'))\n",
    "    .groupBy('delivery_speed')\n",
    "    .agg({\n",
    "        'revenue': 'avg',\n",
    "        'profit': 'avg',\n",
    "    })\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the average lead time of each product considering only the 100 most profitable products?\n",
    "\n",
    "***Hint:*** Break down the problem into smaller steps.\n",
    "\n",
    "First, calculate the average profit and lead time for each product\n",
    "Then select only the 100 most profitable products and select the average lead time for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_orders_products\n",
    "    .groupBy('product_id')\n",
    "    .agg(\n",
    "        f.avg('profit').alias('avg_profit'),\n",
    "        f.avg('lead_time').alias('avg_lead_time'),\n",
    "    )\n",
    "    .orderBy(f.desc('avg_profit'))\n",
    "    .limit(100)\n",
    "    .select(\n",
    "        'product_id',\n",
    "        'avg_lead_time'\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the variance of total revenue generated per month in each country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_orders_products\n",
    "    .groupBy(['order_month', 'supplier_country'])\n",
    "    .agg(f.variance('revenue').alias('revenue_variance'))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How many orders of each product category were placed, considering only orders with a number of days to delivery slower than the median?\n",
    "\n",
    "***Hint:*** Start by calculating the median delivery speed separately. Look into the [documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html) to find the right function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_delivery_speed = df_orders_products.stat.approxQuantile('days_to_delivery', [0.5], 0.01)[0]\n",
    "\n",
    "(\n",
    "    df_orders_products\n",
    "    .filter(f.col('days_to_delivery') > median_delivery_speed)\n",
    "    .groupBy('product_category')\n",
    "    .count()\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How many orders were placed on each day of the week, considering only orders placed in the first half of each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_orders_products\n",
    "    .filter(f.col('order_month') <= 6)\n",
    "    .groupBy('order_day_of_week')\n",
    "    .count()\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How many unique products were announced in each supplier continent before 15-05-2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_orders_products\n",
    "    .filter(\n",
    "        f.col('announcement_date') < f.to_date(f.lit('2014-05-15'))\n",
    "    )\n",
    "    .groupBy('supplier_continent')\n",
    "    .agg(\n",
    "        f.countDistinct('product_id').alias('number_of_products')\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How many orders in each supplier country had a delivery delay greater than the global average delivery delay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert delivery date to unix timestamp to apply the average function\n",
    "avg_delivery_date = (\n",
    "    df_orders_products\n",
    "    .select(f.avg(f.col('days_to_delivery')))\n",
    "    .first()\n",
    ")[0]\n",
    "\n",
    "(\n",
    "    df_orders_products\n",
    "    .filter(f.col('days_to_delivery') > avg_delivery_date)\n",
    "    .groupBy('supplier_country')\n",
    "    .count()\n",
    ").display()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
