# lp-big-data

Welcome to the Big Data specialization!

This collection of modules is designed to help you learn how to work with Big Data using Apache Spark and PySpark. The modules cover a range of topics, from the basics of Spark to more advanced concepts. Each module includes hands-on exercises to help you practice and understand the material, giving you the skills you need to manage and analyze large datasets effectively.


## Modules

1. **Spark Introduction**

    Covers the basics of Apache Spark, including its architecture, key components, and the fundamentals of working with Spark to handle Big Data. Also introduces the Databricks environment and PySpark RDDs.

2. **PySpark DataFrames**

    Explores the creation and manipulation of DataFrames in PySpark for data processing and analysis.

3. **PySpark Advanced**

    Introduces advanced PySpark topics such as User-Defined Functions (UDFs), window functions, and working with complex data structures like arrays and structs.

4. **Final Project**

    To be determined.


## Running Notebooks in Databricks Community Edition

These notebooks are expected to be run in the **Databricks Community Edition**. Detailed steps to set up and configure your environment are provided within the notebooks. Follow these instructions to ensure you have the necessary setup to run the notebooks successfully.

## Suggested learning calendar

### Weeks 1 and 2 (~4 hours): Spark Introduction Module

- **Week 1:** Big data and Spark + Databricks environment
- **Week 2:** PySpark RDDs

### Weeks 3-5 (~6 hours): PySpark DataFrames Module

- **Week 3:** PySpark for Data Preprocessing
- **Week 4:** PySpark for Data Analytics Part 1
- **Week 5:** PySpark for Data Analytics Part 2

### Weeks 6-8 (~6 hours): PySpark Advanced Module

- **Week 6:** Window Function
- **Week 7:** Complex Data Types
- **Week 8:** UDFs

### Weeks 9 and 10 (~4 hours): Final Project

### Weeks 11 and 12: To be determined