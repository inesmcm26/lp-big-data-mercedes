{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Note:** Initialize a cluster with runtime 13.3 LTS and spark version 3.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "Let's do a quick recap of the project: \n",
    "- You'll be working with the [Google Analytics Sample dataset](https://console.cloud.google.com/marketplace/product/obfuscated-ga360-data/obfuscated-ga360-data?inv=1&invt=AbmlmQ), which contains real data from the [Google Merchandise Store](https://shop.googlemerchandisestore.com/), a real ecommerce store that sells Google-branded merchandise. This data is similar to what you deal with in your day-to-day work as a data analyst.\n",
    "- In Part 1 you downloaded the data, preprocessed it and answered some simple analytics questions.\n",
    "- In Part 2 you answered more complex analytics questions.\n",
    "\n",
    "### Part 3 - Sequential Analysis\n",
    "\n",
    "In this final part of the project you will do sequential analysis. This type of analysis enables you to monitor the behavior of users in a session.\n",
    "\n",
    "### Task Completion and Validation\n",
    "Throughout the notebooks, you will be asked to complete a series of tasks and answer questions. Youâ€™ll encounter empty cells where you need to implement the solution, as well as commented-out cells that you should uncomment and fill in with your responses. Afterward, assertion cells will check whether you've completed the tasks correctly.\n",
    "\n",
    "This way you can have immediate feedback on your work, and you can ask questions if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "If you have completed the first part of this project, you should already have the data saved in the DBFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = spark.read.parquet('/FileStore/final_project/ga_sessions_main.parquet')\n",
    "df_hits = spark.read.parquet('/FileStore/final_project/ga_sessions_hits.parquet')\n",
    "df_network = spark.read.parquet('/FileStore/final_project/ga_sessions_network.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] In case you don't have the data yet, run the cells bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh wget https://raw.githubusercontent.com/inesmcm26/lp-big-data-mercedes/main/data/ga_sessions.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh unzip ga_sessions.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.cp('file:/databricks/driver/ga_sessions_main.parquet', 'dbfs:/FileStore/final_project/ga_sessions_main.parquet')\n",
    "dbutils.fs.cp('file:/databricks/driver/ga_sessions_network.parquet', 'dbfs:/FileStore/final_project/ga_sessions_network.parquet')\n",
    "dbutils.fs.cp('file:/databricks/driver/ga_sessions_hits.parquet', 'dbfs:/FileStore/final_project/ga_sessions_hits.parquet')\n",
    "\n",
    "df_main = spark.read.parquet('/FileStore/final_project/ga_sessions_main.parquet')\n",
    "df_hits = spark.read.parquet('/FileStore/final_project/ga_sessions_hits.parquet')\n",
    "df_network = spark.read.parquet('/FileStore/final_project/ga_sessions_network.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Run the cells bellow to apply the data cleaning operations you implemented in the first part of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = (\n",
    "    df_main\n",
    "    .fillna('Direct', subset=['channelGrouping'])\n",
    ")\n",
    "\n",
    "df_network = (\n",
    "    df_network\n",
    "    .withColumn(\n",
    "        'geoNetwork',\n",
    "        f.col('geoNetwork').withField('continent', f.lower(f.col('geoNetwork').getField('continent')))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Overview\n",
    "\n",
    "The column that identifies a session and is **common to all tables** is the `sessionId` column.\n",
    "\n",
    "\n",
    "**Main dataset:**\n",
    "Besides the session id, the main dataset contains the following columns:\n",
    "- **visitorId**: The unique identifier for a visitor\n",
    "- **visitNumber**: The visit number of this visitor. If this is the first visit to the website, then this is set to 1.\n",
    "- **visitStartTime**: The timestamp (expressed as POSIX time) of the beginning of the session\n",
    "- **totals**: A struct with statistics about the session, such as total number of hits, time on site, number of transactions and revenue, etc.\n",
    "- **channelGrouping**: The channel via which the user came to the Store\n",
    "\n",
    "**Hits dataset:**\n",
    "Besides the session id, the hits dataset contains the following column:\n",
    "- **hits**: An array of structs representing all the hits in this session. A hit is an interaction that results in data being sent to Google Analytics. It can either be a page visit or an interaction with some page element. Each struct is a hit defined by the following fields:\n",
    "    - **hitNumber**: The number of this hit in the session\n",
    "    - **type**: Type of the hit: 'PAGE' (Page visit) or 'EVENT' (Interaction with some element on the page)\n",
    "    - **hour**: Hour of the hit\n",
    "    - **minute**: Minute of the hit\n",
    "    - **time**: Time spent on the hit\n",
    "    - **page**: Structured information about the page\n",
    "    - **contentGroup**: Information about the content categorization of the page on the website\n",
    "    - **product**: Array of structs with product information of all products displayed on the page\n",
    "    - **eventInfo**: If hit is of type 'EVENT', this field contains information about the event\n",
    "    - **promotion**: Array of structs with promotion information of all promotions displayed on the page.\n",
    "    - **promotionActionInfo**: Present when there is a promotion on the hit. It explains whether the promotion was clicked (which corresponds to a hit of type 'EVENT' and this event is a 'Promotion Click'), or the promotion is just viewed on the page but was not clicked. \n",
    "    - **transaction**: Information about the transaction when the hit is an event 'Confirm Checkout'. Null otherwise.\n",
    "\n",
    "**Network dataset:** Besides the session id, the network dataset contains the following columns:\n",
    "\n",
    "- **trafficSource**: A struct with information about the source of the session, as well as adds and campaign information\n",
    "- **device**: A struct with information about the device used in the session\n",
    "- **geoNetwork**: A struct with information about the geographic location of the user. Most of this information is obscured and only city, country and country are available.\n",
    "- **customDimensions**: Extra traffic information. You can ignore this column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions path analysis - Simple analysis\n",
    "\n",
    "To analyze the sessions path and understand where users are most lost in the process, we'll calculate the number and percentage of sessions that stop at each stage of the sequence: Home -> Item -> Shopping Cart -> Payment Method -> Checkout Confirmation.\n",
    "\n",
    "Each of this type of page is identified by a `pagePathLevel1`. This is a field of the `page` struct in the `hits` column. We should use the page path instead of the page title to identify the page on a hit mostly beacuse each item page has a different title, but the `pagePathLevel1` is the same for all items.\n",
    "\n",
    "| Page | pagePathLevel1 |\n",
    "| - | - |\n",
    "| Home | /home |\n",
    "| Item | /google+redesign/ |\n",
    "| Shopping Cart | /basket.html|\n",
    "| Payment Method | /payment.html |\n",
    "| Checkout Confirmation | /ordercompleted.html |\n",
    "\n",
    "We want to calculate the number and percentage of sessions that reached each stage to understand where users are most lost in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The way you currently do it\n",
    "\n",
    "Your current approach to this analysis relies on SQL syntax and functionalities. This method requires creating separate tables for each page type and performing multiple left joins to track the sequence of hits.\n",
    "\n",
    "To begin, we'll transform the hits table into a more familiar format: one row per hit. We'll focus on extracting only the essential information from each hit:\n",
    "- Session ID\n",
    "- Hit number\n",
    "- pagePathLevel1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_hits = (\n",
    "    df_hits\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        f.inline('hits')\n",
    "    )\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        'hitNumber',\n",
    "        f.col('page').getField('pagePathLevel1').alias('pagePath')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_exploded_hits.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create separate table for the hits corresponding to each page and then perform multiple left joins to track the progression through the sequence.\n",
    "\n",
    "This corresponds to the following SQL code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register PySpark DataFrame as SQL temporary view to manipulate it with SQL syntax\n",
    "df_exploded_hits.createOrReplaceTempView('hits_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "WITH filtered_hits AS (\n",
    "  SELECT sessionId, pagePath, hitNumber\n",
    "  FROM hits_view\n",
    "  WHERE pagePath IN (\"/home\", \"/google+redesign/\", \"/basket.html\", \"/yourinfo.html\", \"/payment.html\", \"/revieworder.html\", \"/ordercompleted.html\")\n",
    "),\n",
    "home_hits AS (\n",
    "  SELECT sessionId, hitNumber\n",
    "  FROM filtered_hits\n",
    "  WHERE pagePath == \"/home\"\n",
    "),\n",
    "item_hits AS (\n",
    "  SELECT sessionId, hitNumber\n",
    "  FROM filtered_hits\n",
    "  WHERE pagePath == \"/google+redesign/\"\n",
    "),\n",
    "basket_hits AS (\n",
    "  SELECT sessionId, hitNumber\n",
    "  FROM filtered_hits\n",
    "  WHERE pagePath == \"/basket.html\"\n",
    "),\n",
    "payment_hits AS (\n",
    "  SELECT sessionId, hitNumber\n",
    "  FROM filtered_hits\n",
    "  WHERE pagePath == \"/payment.html\"\n",
    "),\n",
    "order_completed_hits AS (\n",
    "  SELECT sessionId, hitNumber\n",
    "  FROM filtered_hits\n",
    "  WHERE pagePath == \"/ordercompleted.html\"\n",
    "),\n",
    "uni AS (\n",
    "  SELECT\n",
    "    home_hits.sessionId AS home_sessionId, \n",
    "    item_hits.sessionId AS item_sessionId,\n",
    "    basket_hits.sessionId AS basket_sessionId,\n",
    "    payment_hits.sessionId AS payment_sessionId,\n",
    "    order_completed_hits.sessionId AS order_completed_sessionId\n",
    "  FROM home_hits\n",
    "  LEFT JOIN item_hits ON home_hits.sessionId == item_hits.sessionId AND home_hits.hitNumber < item_hits.hitNumber\n",
    "  LEFT JOIN basket_hits ON home_hits.sessionId == basket_hits.sessionId AND item_hits.hitNumber < basket_hits.hitNumber\n",
    "  LEFT JOIN payment_hits ON home_hits.sessionId == payment_hits.sessionId AND basket_hits.hitNumber < payment_hits.hitNumber\n",
    "  LEFT JOIN order_completed_hits ON home_hits.sessionId == order_completed_hits.sessionId AND payment_hits.hitNumber < order_completed_hits.hitNumber\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  COUNT(DISTINCT home_sessionId) AS total_home,\n",
    "  COUNT(DISTINCT item_sessionId) AS total_item,\n",
    "  (COUNT(DISTINCT item_sessionId) / COUNT(DISTINCT home_sessionId)) * 100 AS 1st_2nd,\n",
    "  COUNT(DISTINCT basket_sessionId) AS basket_item,\n",
    "  (COUNT(DISTINCT basket_sessionId) / COUNT(DISTINCT item_sessionId)) * 100 AS 2nd_3rd,\n",
    "  COUNT(DISTINCT payment_sessionId) AS payment_item,\n",
    "  (COUNT(DISTINCT payment_sessionId) / COUNT(DISTINCT basket_sessionId)) * 100 AS 3th_4th,\n",
    "  COUNT(DISTINCT order_completed_sessionId) AS order_completed_item,\n",
    "  (COUNT(DISTINCT order_completed_sessionId) / COUNT(DISTINCT payment_sessionId)) * 100 AS 4th_5th\n",
    "FROM uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the next cell you can find the equivalent code in PySpark. Let's run the code and count much time it takes to finish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Create the exploded hits dataframe\n",
    "df_exploded_hits = (\n",
    "    df_hits\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        f.inline('hits')\n",
    "    )\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        'hitNumber',\n",
    "        f.col('page').getField('pagePathLevel1').alias('pagePath')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filter hits based on specific page paths\n",
    "filtered_hits = (\n",
    "    df_exploded_hits\n",
    "    .filter(\n",
    "        f.col('pagePath').isin(\n",
    "            '/home',\n",
    "            '/google+redesign/',\n",
    "            '/basket.html',\n",
    "            '/payment.html',\n",
    "            '/ordercompleted.html'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create individual DataFrames for each page path\n",
    "home_hits = (\n",
    "    filtered_hits\n",
    "    .filter(f.col('pagePath') == '/home')\n",
    "    .select(\n",
    "        f.col('sessionId').alias('home_sessionId'),\n",
    "        f.col('hitNumber').alias('home_hitNumber')\n",
    "    )\n",
    ")\n",
    "item_hits = (\n",
    "    filtered_hits\n",
    "    .filter(f.col('pagePath') == '/google+redesign/')\n",
    "    .select(\n",
    "        f.col('sessionId').alias('item_sessionId'),\n",
    "        f.col('hitNumber').alias('item_hitNumber')\n",
    "    )\n",
    ")\n",
    "basket_hits = (\n",
    "    filtered_hits\n",
    "    .filter(f.col('pagePath') == '/basket.html')\n",
    "    .select(\n",
    "        f.col('sessionId').alias('basket_sessionId'),\n",
    "        f.col('hitNumber').alias('basket_hitNumber')\n",
    "    )\n",
    ")\n",
    "payment_hits = (\n",
    "    filtered_hits\n",
    "    .filter(f.col('pagePath') == '/payment.html')\n",
    "    .select(\n",
    "        f.col('sessionId').alias('payment_sessionId'),\n",
    "        f.col('hitNumber').alias('payment_hitNumber')\n",
    "    )\n",
    ")\n",
    "order_completed_hits = (\n",
    "    filtered_hits\n",
    "    .filter(f.col('pagePath') == '/ordercompleted.html')\n",
    "    .select(\n",
    "        f.col('sessionId').alias('order_completed_sessionId'),\n",
    "        f.col('hitNumber').alias('order_completed_hitNumber')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Perform left joins in sequence\n",
    "uni = (\n",
    "    home_hits\n",
    "    .join(\n",
    "        item_hits,\n",
    "        on=[(home_hits.home_sessionId == item_hits.item_sessionId)\n",
    "            & (home_hits.home_hitNumber < item_hits.item_hitNumber)\n",
    "        ],\n",
    "        how='left'\n",
    "    )\n",
    "    .join(\n",
    "        basket_hits,\n",
    "        on=[(home_hits.home_sessionId == basket_hits.basket_sessionId)\n",
    "            & (item_hits.item_hitNumber < basket_hits.basket_hitNumber)\n",
    "        ],\n",
    "        how='left'\n",
    "    )\n",
    "    .join(\n",
    "        payment_hits,\n",
    "        on=[(home_hits.home_sessionId == payment_hits.payment_sessionId)\n",
    "            & (basket_hits.basket_hitNumber < payment_hits.payment_hitNumber)\n",
    "        ],\n",
    "        how='left'\n",
    "    )\n",
    "    .join(\n",
    "        order_completed_hits,\n",
    "        on=[(home_hits.home_sessionId == order_completed_hits.order_completed_sessionId)\n",
    "            & (payment_hits.payment_hitNumber < order_completed_hits.order_completed_hitNumber)\n",
    "        ],\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate the conversion rates\n",
    "result = (\n",
    "    uni.select(\n",
    "        f.countDistinct('home_sessionId').alias('total_home'),\n",
    "        f.countDistinct('item_sessionId').alias('total_item'),\n",
    "        f.countDistinct('basket_sessionId').alias('total_basket'),\n",
    "        f.countDistinct('payment_sessionId').alias('total_payment'),\n",
    "        f.countDistinct('order_completed_sessionId').alias('total_order_completed')\n",
    "    )\n",
    "    .withColumn('1st_2nd', (f.col('total_item') / f.col('total_home')) * 100)\n",
    "    .withColumn('2nd_3rd', (f.col('total_basket') / f.col('total_item')) * 100)\n",
    "    .withColumn('3th_4th', (f.col('total_payment') / f.col('total_basket')) * 100)\n",
    "    .withColumn('4th_5th', (f.col('total_order_completed') / f.col('total_payment')) * 100)\n",
    ")\n",
    "\n",
    "result.display()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "joins_time = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The UDFs way\n",
    "\n",
    "Now let's see a different approach using PySpark that eliminates the need for multiple left joins. We'll be using User Defined Functions (UDFs).\n",
    "\n",
    "Let's start by creating a function that receives an array of hits and returns 1 if the hit was on a `item` page after there was a hit on the `home` page, and 0 otherwise. Then we'll register this function as a UDF. After that, we'll create a new boolean column on the hits dataframe that is the result of applying this UDF to the `hits` column.\n",
    "\n",
    "It is easier to use UDFs on top of the original hits dataframe rather than the exploded one. Since we have one row for each session, and each row has an array of hits, we can iterate through the array using python, and it becomes easy to deal with this complex column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "@f.udf(IntegerType())\n",
    "def item_after_home(hits):\n",
    "    # Hits is a list of dictionaries\n",
    "    visited_home = False\n",
    "    \n",
    "    for hit in hits:\n",
    "        page_path = hit['page']['pagePathLevel1']\n",
    "        if page_path == '/home':\n",
    "            visited_home = True\n",
    "        \n",
    "        if visited_home and page_path == '/google+redesign/':\n",
    "            return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "df_hits_item_after_home = (\n",
    "    df_hits\n",
    "    .withColumn('item_after_home', item_after_home(f.col('hits')))\n",
    ")\n",
    "\n",
    "df_hits_item_after_home.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to elaborate on that function. Instead of returning just a 1 or a 0, we'll return an array of 1's and 0's, one for each stage.\n",
    "\n",
    "To make it more clear:\n",
    "- The first element of the array should be True if there is a hit on the `home` page.\n",
    "- The second element should be True if there is a hit on an `item` page after there was a hit on the `home` page.\n",
    "- The third element should be True if there is a hit on the `basket` page after there was a hit on an `item` page, which, in turn, was after a hit on the `home` page.\n",
    "- etc.\n",
    "\n",
    "After that, we can register this function as a UDF and apply it to the `hits` column on the hits dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, ArrayType\n",
    "\n",
    "@f.udf(ArrayType(IntegerType()))\n",
    "def stages(hits):\n",
    "    result = []\n",
    "\n",
    "    home = 0\n",
    "    item_after_home = 0\n",
    "    basket_after_item = 0\n",
    "    payment_after_basket = 0\n",
    "    order_completed_after_payment = 0\n",
    "    \n",
    "    for hit in hits:\n",
    "        page_path = hit['page']['pagePathLevel1']\n",
    "\n",
    "        if page_path == '/home':\n",
    "            home = 1\n",
    "        \n",
    "        if home and (page_path == '/google+redesign/'):\n",
    "            item_after_home = 1\n",
    "        \n",
    "        if item_after_home and (page_path == '/basket.html'):\n",
    "            basket_after_item = 1\n",
    "        \n",
    "        if basket_after_item and (page_path == '/payment.html'):\n",
    "            payment_after_basket = 1\n",
    "        \n",
    "        if payment_after_basket and page_path == '/ordercompleted.html':\n",
    "            order_completed_after_payment = 1 \n",
    "\n",
    "    # Store results in a list\n",
    "    result = [\n",
    "        home,\n",
    "        item_after_home,\n",
    "        basket_after_item,\n",
    "        payment_after_basket,\n",
    "        order_completed_after_payment\n",
    "    ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "df_stages = (\n",
    "    df_hits\n",
    "    .withColumn('stages', stages(f.col('hits')))\n",
    ")\n",
    "\n",
    "df_stages.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a boolean column for each stage. This means create one column for each array element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stages_cols = (\n",
    "    df_stages\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        f.element_at('stages', 1).alias('home_seen'),\n",
    "        f.element_at('stages', 2).alias('item_after_home'),\n",
    "        f.element_at('stages', 3).alias('basket_after_item'),\n",
    "        f.element_at('stages', 4).alias('payment_after_basket'),\n",
    "        f.element_at('stages', 5).alias('order_completed_after_payment'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a dataframe where each row represents a single session, and we can clearly see which stages were reached during that session.\n",
    "\n",
    "To calculate the number of sessions that reached each stage we just need to count the number of sessions where each stage column is 1.\n",
    "\n",
    "After this, we can calculate the percentage of sessions that reached each stage from the previous one. This is done by dividing the number of sessions that reach a stage by the number of sessions that reached the previous stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    df_stages_cols\n",
    "    .agg(\n",
    "        f.sum(\"home_seen\").alias(\"total_home\"),\n",
    "        f.sum(\"item_after_home\").alias(\"total_item_after_home\"),\n",
    "        f.sum(\"basket_after_item\").alias(\"total_basket_after_item\"),\n",
    "        f.sum(\"payment_after_basket\").alias(\"total_payment_after_basket\"),\n",
    "        f.sum(\"order_completed_after_payment\").alias(\"total_order_completed_after_payment\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"item_after_home_ratio\",  f.col(\"total_item_after_home\") / f.col(\"total_home\")\n",
    "    ).withColumn(\n",
    "        \"basket_after_item_ratio\",  f.col(\"total_basket_after_item\") / f.col(\"total_item_after_home\")\n",
    "    ).withColumn(\n",
    "        \"payment_after_basket_ratio\", f.col(\"total_payment_after_basket\") / f.col(\"total_basket_after_item\")\n",
    "    ).withColumn(\n",
    "        \"order_completed_after_payment_ratio\", \n",
    "        f.col(\"total_order_completed_after_payment\") / f.col(\"total_payment_after_basket\")\n",
    "    )\n",
    ")\n",
    "\n",
    "result.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run everything at once and count how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "result = (\n",
    "    df_hits\n",
    "    .withColumn('stages', stages(f.col('hits')))\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        f.element_at('stages', 1).alias('home_seen'),\n",
    "        f.element_at('stages', 2).alias('item_after_home'),\n",
    "        f.element_at('stages', 3).alias('basket_after_item'),\n",
    "        f.element_at('stages', 4).alias('payment_after_basket'),\n",
    "        f.element_at('stages', 5).alias('order_completed_after_payment'),\n",
    "    )\n",
    "    .agg(\n",
    "        f.sum(\"home_seen\").alias(\"total_home\"),\n",
    "        f.sum(\"item_after_home\").alias(\"total_item_after_home\"),\n",
    "        f.sum(\"basket_after_item\").alias(\"total_basket_after_item\"),\n",
    "        f.sum(\"payment_after_basket\").alias(\"total_payment_after_basket\"),\n",
    "        f.sum(\"order_completed_after_payment\").alias(\"total_order_completed_after_payment\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"item_after_home_ratio\",  f.col(\"total_item_after_home\") / f.col(\"total_home\")\n",
    "    ).withColumn(\n",
    "        \"basket_after_item_ratio\",  f.col(\"total_basket_after_item\") / f.col(\"total_item_after_home\")\n",
    "    ).withColumn(\n",
    "        \"payment_after_basket_ratio\", f.col(\"total_payment_after_basket\") / f.col(\"total_basket_after_item\")\n",
    "    ).withColumn(\n",
    "        \"order_completed_after_payment_ratio\", \n",
    "        f.col(\"total_order_completed_after_payment\") / f.col(\"total_payment_after_basket\")\n",
    "    )\n",
    ")\n",
    "\n",
    "result.display()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "udf_time = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using UDFs is an alternative way of finding out if a session reached a certain stage.\n",
    "\n",
    "You may find it more intuitive to deal with an array of hits and iterate through it, rather than have one row per hit and using window functions or even doing multiple left joins to track a sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The PySpark built-in functions way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how we could achieve the same resulting using only PySpark built-in functions.\n",
    "\n",
    "This approach requires more steps and a more complex reasoning than using UDF's. You'll be guided through each step to achieve the final result. The aim is not to challenge your thinking process, but rather to show that PySpark offers tools and syntax that allow you to perform the same analysis without the need for joins or UDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with the exploded hits dataframe: the dataframe that has one row per session hit.\n",
    "\n",
    "First, let's start by adding a new boolean column to the `df_exploded_hits` dataframe for each page path, which indicates if the hit is on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages_flag = (\n",
    "    df_exploded_hits\n",
    "    .withColumn(\"is_home\", (f.col(\"pagePath\") == \"/home\"))\n",
    "    .withColumn(\"is_item\", (f.col(\"pagePath\") == \"/google+redesign/\"))\n",
    "    .withColumn(\"is_basket\", (f.col(\"pagePath\") == \"/basket.html\"))\n",
    "    .withColumn(\"is_payment\", (f.col(\"pagePath\") == \"/payment.html\"))\n",
    "    .withColumn(\"is_order_completed\", (f.col(\"pagePath\") == \"/ordercompleted.html\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a dataframe called `df_stages` with the following columns:\n",
    "- `home_seen`: boolean column that is true if the hit happened after a hit on the home page.\n",
    "- `items_after_home`: boolean column that is true if the hit is on an item page and the home page has been seen.\n",
    "- `basket_after_item`: boolean column that is true if the hit is on the basket page and there was a **previous hit on an item page, which, in turn, had a previous hit on the home page**.\n",
    "- `payment_after_basket`: boolean column that is true if the hit is on the payment page and there was a previous hit on the home, item and basket pages in sequence\n",
    "- `order_completed_after_payment`: boolean column that indicates if the hit is on the order completed page and there was a previous hit on the home, item, basket and payment pages in sequence\n",
    "\n",
    "**NOTES:**\n",
    "- Columns should be created one after the other. The column created in the previous step should be used to create the new column.\n",
    "- To create some of these columns, we need to use a window that goes from the current hit to the first hit of the session.\n",
    "- The function to be applied over the window needs to be a window function that returns True if some condition verifies. The condition is that there was a previous hit on the page we're interested in, and that hit was preceded by another hit on another page, and so on.\n",
    "\n",
    "**HINT**:\n",
    "- The function `f.max`, when applied to a boolean column, returns True if at least one value on that column is True, and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"sessionId\").orderBy(\"hitNumber\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "df_stages = (\n",
    "    df_pages_flag\n",
    "    .withColumn(\"home_seen\", f.max(\"is_home\").over(window))\n",
    "    .withColumn(\"item_after_home\", f.col('is_item') & f.col('home_seen'))\n",
    "    .withColumn(\"basket_after_item\", f.col('is_basket') & f.max('item_after_home').over(window))\n",
    "    .withColumn(\"payment_after_basket\",\n",
    "                f.col(\"is_payment\") & f.max('basket_after_item').over(window)\n",
    "    )\n",
    "    .withColumn(\"order_completed_after_payment\",\n",
    "                f.col(\"is_order_completed\") & f.max('payment_after_basket').over(window)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have information on whether a hit on a page was preceded by hits on all previous pages in the sequence. This data is enough to calculate the number of sessions that reached each stage of the sequence.\n",
    "\n",
    "The boolean columns we created indicate whether a certain stage was reached in a session. For instance, if a session has a hit with a True value in the `order_completed_after_payment` column, it means that the session reached the final stage of the sequence. This is because for this value to be True, there must have been a previous hit on a `payment` page with a True value in the `payment_after_basket` column, and so on, tracing back through the entire funnel.\n",
    "\n",
    "Now let's take a moment to consider something. It does not matter if there is more than one hit on an `item` page after a hit on the `home` page in some session, for example. We only need at least one hit on each page that respects the sequence to consider that the session reached a certain stage.\n",
    "\n",
    "Therefore, to calculate the number of sessions that reached each stage, we need to count the number of **distinct** sessions where each of these columns is true.\n",
    "\n",
    "We can store these values either in columns of a final dataframe or in separate variables for printing. \n",
    "\n",
    "After this, we calculate the percentage of sessions that reached each stage from the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    df_stages\n",
    "    .agg(\n",
    "        f.countDistinct(f.when(f.col(\"home_seen\"), f.col(\"sessionId\"))).alias(\"total_home\"),\n",
    "        f.countDistinct(f.when(f.col(\"item_after_home\"), f.col(\"sessionId\"))).alias(\"total_item_after_home\"),\n",
    "        f.countDistinct(f.when(f.col(\"basket_after_item\"), f.col(\"sessionId\"))).alias(\"total_basket_after_item\"),\n",
    "        f.countDistinct(f.when(f.col(\"payment_after_basket\"), f.col(\"sessionId\"))).alias(\"total_payment_after_basket\"),\n",
    "        f.countDistinct(f.when(f.col(\"order_completed_after_payment\"), f.col(\"sessionId\"))).alias(\"total_order_completed_after_payment\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"item_after_home_ratio\",  f.col(\"total_item_after_home\") / f.col(\"total_home\")\n",
    "    ).withColumn(\n",
    "        \"basket_after_item_ratio\",  f.col(\"total_basket_after_item\") / f.col(\"total_item_after_home\")\n",
    "    ).withColumn(\n",
    "        \"payment_after_basket_ratio\", f.col(\"total_payment_after_basket\") / f.col(\"total_basket_after_item\")\n",
    "    ).withColumn(\n",
    "        \"order_completed_after_payment_ratio\", \n",
    "        f.col(\"total_order_completed_after_payment\") / f.col(\"total_payment_after_basket\")\n",
    "    )\n",
    ")\n",
    "\n",
    "result.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's do it all at once and see how long it takes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"sessionId\").orderBy(\"hitNumber\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result = (\n",
    "    df_hits\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        f.inline('hits')\n",
    "    )\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        'hitNumber',\n",
    "        f.col('page').getField('pagePathLevel1').alias('pagePath')\n",
    "    )\n",
    "    .withColumn(\"is_home\", (f.col(\"pagePath\") == \"/home\"))\n",
    "    .withColumn(\"is_item\", (f.col(\"pagePath\") == \"/google+redesign/\"))\n",
    "    .withColumn(\"is_basket\", (f.col(\"pagePath\") == \"/basket.html\"))\n",
    "    .withColumn(\"is_payment\", (f.col(\"pagePath\") == \"/payment.html\"))\n",
    "    .withColumn(\"is_order_completed\", (f.col(\"pagePath\") == \"/ordercompleted.html\"))\n",
    "    .withColumn(\"home_seen\", f.max(\"is_home\").over(window))\n",
    "    .withColumn(\"item_after_home\", f.col('is_item') & f.col('home_seen'))\n",
    "    .withColumn(\"basket_after_item\", f.col('is_basket') & f.max('item_after_home').over(window))\n",
    "    .withColumn(\"payment_after_basket\",\n",
    "                f.col(\"is_payment\") & f.max('basket_after_item').over(window)\n",
    "    )\n",
    "    .withColumn(\"order_completed_after_payment\",\n",
    "                f.col(\"is_order_completed\") & f.max('payment_after_basket').over(window)\n",
    "    )\n",
    "    .agg(\n",
    "        f.countDistinct(f.when(f.col(\"home_seen\"), f.col(\"sessionId\"))).alias(\"total_home\"),\n",
    "        f.countDistinct(f.when(f.col(\"item_after_home\"), f.col(\"sessionId\"))).alias(\"total_item_after_home\"),\n",
    "        f.countDistinct(f.when(f.col(\"basket_after_item\"), f.col(\"sessionId\"))).alias(\"total_basket_after_item\"),\n",
    "        f.countDistinct(f.when(f.col(\"payment_after_basket\"), f.col(\"sessionId\"))).alias(\"total_payment_after_basket\"),\n",
    "        f.countDistinct(f.when(f.col(\"order_completed_after_payment\"), f.col(\"sessionId\"))).alias(\"total_order_completed_after_payment\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"item_after_home_ratio\",  f.col(\"total_item_after_home\") / f.col(\"total_home\")\n",
    "    ).withColumn(\n",
    "        \"basket_after_item_ratio\",  f.col(\"total_basket_after_item\") / f.col(\"total_item_after_home\")\n",
    "    ).withColumn(\n",
    "        \"payment_after_basket_ratio\", f.col(\"total_payment_after_basket\") / f.col(\"total_basket_after_item\")\n",
    "    ).withColumn(\n",
    "        \"order_completed_after_payment_ratio\", \n",
    "        f.col(\"total_order_completed_after_payment\") / f.col(\"total_payment_after_basket\")\n",
    "    )\n",
    ")\n",
    "\n",
    "result.display()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "built_in_time = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now analyse the running times of each approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=['Joins', 'UDF', 'PySpark Built-In Functions'], y=[joins_time, udf_time, built_in_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promotion effectiveness - More complex path analysis\n",
    "\n",
    "In Part 2, question 7, we identified the most clicked promotion in sessions where at least one product was added to the cart.\n",
    "\n",
    "However, we are not sure if clicking the promotion is what lead to the products being added to the cart. \n",
    "\n",
    "So now let's try to understand which promotions actually led to additions to the cart. For that we need to do sequential analysis.\n",
    "\n",
    "We want to find out which promotion led to the most product additions to the cart.\n",
    "\n",
    "Let's start by thinking how we can infer that a product being added to the cart was due to a promotion click:\n",
    "- When a promotion is clicked, the user enters a new page. This corresponds to the following hits: \n",
    "    - 'EVENT' hit, with `eventInfo.eventAction` equal to 'Promotion Click'\n",
    "    - 'PAGE' hit, immediately after the 'EVENT' hit, with a certain `pageTitle`\n",
    "- If the user leaves the page before adding a product to the cart, we conclude that the promotion click did not lead to the product addition.\n",
    "- On the other hand, if the user navigates through the page (for instance, clicks on the 'Quick View' to see the details of a product, etc.), never leaves, and adds a product to the cart, we conclude that the promotion click led to the product addition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using UDFs - The easy way\n",
    "\n",
    "Define a function that receives an array of hits from a session and returns a map where the keys are promotion IDs, and the values represent the number of times each promotion resulted in a product being added to the cart.\n",
    "\n",
    "The function should follow these steps:\n",
    "\n",
    "1. Iterate through the hits:\n",
    "    - When encountering a hit of type 'EVENT' where `eventInfo.eventAction` equals 'Promotion Click', the subsequent hit will be a 'PAGE' hit. Any hits that follow on the same page are considered a result of this promotion click.\n",
    "    - If one of these subsequent hits is of type 'EVENT' and has `eventInfo.eventAction` equal to 'Add to Cart', it indicates that the promotion led to a product being added to the cart.\n",
    "    - Take into consideration that if the user leaves the page meanwhile, the promotion click did not lead to a product addition.\n",
    "2. Update the map:\n",
    "    - Use the promotion ID as the key. If the promotion ID is not already in the map, initialize its value to 1. If the promotion ID already exists, increment its value by 1.\n",
    "\n",
    "Finally, register this function as a UDF (User-Defined Function) and apply it to the `hits` column of the hits dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each session, you already have information about which promotions led to product additions and how many times each promotion contributed to a product being added to the cart.\n",
    "\n",
    "To calculate the total number of product additions driven by each promotion across all sessions:\n",
    "1. Explode the column created with the UDF, so each promotion ID and its count are represented as individual rows.\n",
    "2. Group the exploded data by the promotion ID.\n",
    "3. Aggregate the counts by summing the values for each promotion ID.\n",
    "\n",
    "This will give you the total number of product additions attributed to each promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using PySpark Built-In Functions - The hard way\n",
    "\n",
    "We can do this analysis using PySpark built-in functions. However, it involves more steps than using UDFs and a more complex thought process. \n",
    "\n",
    "So, the first thing we need to identify is 'PAGE' hits that happened after a promotion click.\n",
    "\n",
    "Let's transform the dataframe to a more friendly format: one row per hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_hits = (\n",
    "    df_hits\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        f.inline('hits')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a new column `origin_promo` that has the promotion id of the promotion click hit that originated the 'PAGE' hit. This column will be Null for all hits that did not originate from a promotion click. You can check if a hit originated from a promotion click by checking if the previous hit was a 'EVENT' hit with `eventInfo.eventAction` equal to 'Promotion Click'.\n",
    "\n",
    "Then select only the following columns for simplification:\n",
    "- sessionId\n",
    "- hitNumber\n",
    "- type\n",
    "- page.pageTitle\n",
    "- eventInfo.eventAction\n",
    "- promotion\n",
    "- origin_promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_origin_promo = Window.partitionBy('sessionId').orderBy('hitNumber')\n",
    "\n",
    "df_origin_promo = (\n",
    "    df_exploded_hits\n",
    "    .withColumn('origin_promo',\n",
    "                f.when(\n",
    "                    f.lag(f.col('eventInfo')).over(window_origin_promo).isNotNull()\n",
    "                    & (f.lag(f.col('eventInfo').getField('eventAction')).over(window_origin_promo) == 'Promotion Click'),\n",
    "                    f.lag('promotion').over(window_origin_promo)\n",
    "                ).otherwise(None)\n",
    "    )\n",
    "    .select(\n",
    "        'sessionId',\n",
    "        'type',\n",
    "        'hitNumber',\n",
    "        f.col('page').getField('pageTitle').alias('pageTitle'),\n",
    "        f.col('eventInfo').getField('eventAction').alias('eventAction'),\n",
    "        'promotion',\n",
    "        'origin_promo'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know if a page was reached by a promotion click. However, it is possible that the user entered the same page more than once during the session, once via a promotion click and the other ones via another page. So we need to be able to classify hits on a page into 'page views'. Imagine this scenario:\n",
    "\n",
    "1. The user enters page A via a promotion click. This corresponds to hit number 1.\n",
    "2. The user navigates in page A, which results in multiple hits on that page (hit 2 to 10).\n",
    "3. The user leaves the page.\n",
    "4. The user enters page A again later, this time not via a promotion click. This corresponds to hit number 20.\n",
    "5. The user navigates in page A again, which results in another hits on that page (hit 21 to 23).\n",
    "6. The user adds a product to the cart. This is hit number 24. We can not conclude that the promotion click led to the product addition, since the user left the page meanwhile, before adding the product to the cart.\n",
    "\n",
    "Hits 1-10 correspond to one page view, and hits 20-24 correspond to another page view.\n",
    "\n",
    "Let's create a new column `page_view` that indicates the page view number of the hit. To simplify, this column can be the hit number of the hit that originated the page view. For instance, if the hit that originated the page view is hit number 1, then all hits from 1 to 10 are part of the page view '1'. On the other hand, if the hit that originated the page view is hit number 20, then all hits from 20 to 24 are part of the page view '20'.\n",
    "\n",
    "In our scenario, page view '1' was originated by a promotion click, and page view '20' was not.\n",
    "\n",
    "To create the `page_view` column, we can group the hits by session and page, order them by hit number, and see if the hit numbers are sequential. If there is a break in the sequence, we can assume that a new page view started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_page = Window.partitionBy('sessionId', 'pageTitle').orderBy('hitNumber')\n",
    "\n",
    "df_page_view = (\n",
    "    df_origin_promo\n",
    "    # See if hits on a page are sequential\n",
    "    .withColumn('lastHitNumber', f.lag('hitNumber').over(window_page))\n",
    "    .withColumn('sequential', f.when(f.col('hitNumber') == (f.col('lastHitNumber') + 1), True).otherwise(False))\n",
    "    # Set page view on the first hit of that page view\n",
    "    .withColumn(\n",
    "        'pageView',\n",
    "        f.when(\n",
    "            f.col('sequential') == False,\n",
    "            f.col('hitNumber')\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "    # Propagate the page view to all sequential hits on the page after that one\n",
    "    .withColumn(\n",
    "        'pageView',\n",
    "        f.last('pageView', ignorenulls=True).over(window_page)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, we can now identify all the hits on a page that were originated by a promotion click. These hits correspond to hits of a page view that was itself originated by a promotion click.\n",
    "\n",
    "So we just need to propagate the `origin_promo` value through the hits of a page view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_page_view = Window.partitionBy('sessionId', 'pageTitle', 'pageView').orderBy('hitNumber')\n",
    "\n",
    "df_final = (\n",
    "    df_page_view\n",
    "    .withColumn(\n",
    "        'origin_promo',\n",
    "        f.last('origin_promo', ignorenulls=True).over(window_page_view)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have one row per hit, and we know if that hit was originated by a promotion click and of that hit corresponds to adding a product to the cart.\n",
    "\n",
    "We just need to count the number of times a product was added to the cart because of a certain promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_final\n",
    "    .filter(\n",
    "        (f.col('eventAction') == 'Add to Cart')\n",
    "        & (f.col('origin_promo').isNotNull())\n",
    "    )\n",
    "    .groupBy(f.element_at(f.col('origin_promo'), 1).getField('promoId').alias('promoId'))\n",
    "    .agg(f.count('visitId').alias('nr_purchases'))\n",
    "    .orderBy(f.desc('nr_purchases'))\n",
    ").display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daredata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
