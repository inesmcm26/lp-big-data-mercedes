{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get back to our orders and products datasets and practice window functions!\n",
    "\n",
    "**NOTE:** The orders and products datasets were downloaded and preprocessed on module 2. If you haven't run all the notebooks (including exercises solutions) from module 2, please download the data and save it to the FileStore by running the cells bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "\n",
    "wget https://raw.githubusercontent.com/inesmcm26/lp-big-data-mercedes/refs/heads/main/data/orders-preprocessed.csv\n",
    "wget https://raw.githubusercontent.com/inesmcm26/lp-big-data-mercedes/refs/heads/main/data/products-preprocessed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs cp file:/databricks/driver/orders-preprocessed.csv dbfs:/FileStore/lp-big-data/orders-data/orders-preprocessed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs cp file:/databricks/driver/products-preprocessed.csv dbfs:/FileStore/lp-big-data/orders-data/products-preprocessed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to load and join the datasets and take a look at the final dataset.\n",
    "\n",
    "Next, answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"/FileStore/lp-big-data/orders-data/orders-preprocessed.csv\")\n",
    ")\n",
    "\n",
    "df_products = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"/FileStore/lp-big-data/orders-data/products-preprocessed.csv\")\n",
    ")\n",
    "\n",
    "df_orders_products = (\n",
    "    df_orders.join(\n",
    "        df_products,\n",
    "        on=['product_id'],\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "df_orders_products.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rank each customer based on the total amount of ordered products.\n",
    "\n",
    "The ranking should have no gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each order placed by a customer, what is the difference in days between the order's placing date and the placing date of their previous order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each order placed by a customer, what is the difference in revenue between the current order and the customer's previous three orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the yearly average profit increase or decrease (difference between year Y and year Y-1) for each supplier?\n",
    "\n",
    "The average profit for a supplier is determined by calculating the average profit from all orders of products supplied by that supplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **BONUS** Calculate the cumulative sum of average revenue generated by each customer over the years\n",
    "\n",
    "Hint: Check the `rowsBetween()` documentation [here](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Window.rowsBetween.html#pyspark.sql.Window.rowsBetween)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
